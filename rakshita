Literature Review

I
"Drone Deployed Speaker System" (US Patent Application US20190176982A1):
The paper presents a unique approach by integrating speaker systems directly into drones, enabling flexible and autonomous audio deployments.Traditionally, setting up speaker systems in indoor or outdoor spaces is a static, manual process. It involves trial-and-error placement, acoustic calibration, and often expert knowledge to handle issues like echo, dead zones, and room shape. Although existing technologies—like beamforming and spatial audio tuning—have improved sound optimization, these solutions are tied to fixed speaker placements.
The paper proposes a system of Drone Speaker Units (DSUs)—drones that have built-in speakers and aerial navigation capabilities. These drones autonomously fly, map the environment using sensors (such as LiDAR), and then either hover or perch at optimal locations to broadcast sound. The key features of the system include:
Environmental Mapping: Using onboard sensors, the drones generate a 3D spatial map of the room or area.

Autonomous Positioning: Drones choose stable and acoustically suitable perching points (e.g., ceiling beams, shelves) or hover in midair.

Flight Planning: A control system directs each drone to its target location and coordinates between them.

Dynamic Sound Calibration: The drones can reconfigure their positions in real time if the environment changes—like if furniture is moved or the audience shifts.

This technology enables rapid, scalable deployment of speaker systems without manual installation or expert tuning. It’s useful in various scenarios, such as:
Home theaters, where drones can optimize sound based on room layout.

Public address systems, like those used at events or rallies.

Emergency communication, especially in locations lacking infrastructure (e.g., disaster zones).

Virtual or augmented reality environments, where the sound field can adjust to user movement.

Concerts or outdoor venues, where drones can create surround sound without the need for permanent rigs.

Unlike modular speaker systems (like Sonos), which require manual setup and lack mobility, this drone-based system moves and adjusts itself automatically, providing true adaptability. It reduces human effort, saves setup time, and allows the sound environment to evolve dynamically.


II
"UAS Surveillance and Communication Package" (US Patent Application US20190166420A1):
This paper introduces a compact, self-contained accessory payload that transforms commercially available drones into multi-functional platforms, extending their operational utility without requiring internal drone modifications.
Traditional surveillance drones are typically limited to video capture and telemetry, often falling short in dynamic law enforcement, emergency response, and tactical environments. Enhancements, when available, tend to be costly, heavy, and tailored to specific drone models, limiting flexibility. This research addresses these shortcomings by proposing a detachable module that includes a processor-controlled system with lighting, audio, and communication subsystems.
Key innovations of the system include:
Bi-directional audio communication via directional and omnidirectional microphones and speakers,

Lighting systems for both illumination and tactical distraction using strobing or colored LEDs,

Independent operation through an onboard power source (e.g., CR123A battery), minimizing impact on drone flight time,

Compatibility with off-the-shelf drones, such as the DJI Mavic Pro, enabling affordable deployment and scalability.

Earlier literature has emphasized drone-based video surveillance and environmental monitoring. However, integration of real-time audio interaction and psychological disruption features (e.g., distraction lights) is novel and particularly suited for urban tactical missions, hostage negotiation, crowd control, or search-and-rescue (SAR) in compromised visibility.
The payload's modularity and minimal impact on drone aerodynamics make it well-suited for rapid mission configuration. By separating the control logic and communications from the drone's core systems, the design also improves redundancy and fail-safe operations. This stands in contrast to previous attempts at onboard system expansion, which often resulted in power draw conflicts, system instability, or firmware compatibility issues.
Further, the package’s capability to collect audio with noise cancellation—while minimizing interference from rotor noise—is a notable technical advancement. The ability to capture clean field audio or issue remote verbal commands enhances situational awareness and enables real-time human-drone interaction in challenging or hazardous environments.


III 
“System for Recording and Synchronizing Audio and Video Associated with a UAV Flight” (US10535372B2)
Recent developments in unmanned aerial vehicle (UAV) technologies have broadened their use in filmmaking, live reporting, and surveillance. However, one of the persistent challenges in UAV videography is the synchronization of audio and video streams captured from different sources and locations. Traditional methods—like using clapperboards or relying on Wi-Fi-based timecodes—are susceptible to inaccuracies due to clock drift, delays, or weak connectivity, particularly in outdoor or remote environments.
The paper addresses this problem with a novel system that ensures accurate synchronization of audio and video tracks recorded from UAVs and separate ground-based devices. The core innovation lies in using GPS-derived timestamps embedded in both audio and video recordings. These timestamps are generated using:
A GPS receiver for accurate universal time,

A real-time clock for synchronization events,

Time-pulsed triggers to start recording, and

Video encoders to embed metadata with absolute timing.

Prior literature and systems have primarily focused on onboard video and sound, but did not effectively support multi-device synchronization using a global reference clock. This invention circumvents the common issue of signal drift by aligning both tracks in post-processing using high-precision absolute timestamps rather than relative cues like audio claps or wireless triggers.
Moreover, the system includes practical enhancements such as a UAV-mounted speaker for producing synchronization signals, integration with smartphones, and flexible merging options through onboard, smartphone, or server-based software. It is particularly relevant for industries requiring high-fidelity multimedia capture, such as professional filmmaking, documentation, and remote interviews.
In essence, this patent contributes a robust and modular solution for precise media synchronization, improving usability and reliability across UAV-enabled applications where capturing synchronized audiovisual content is crucial.



IV
“Drone Audition: Loudspeaker Interior Response Modeling for Making Drones Talk” 
Human-drone interaction is evolving, with an emerging research frontier aimed at enabling drones not only to hear (audition) but also to speak. The work by Manamperi et al. (2024) explores this frontier by investigating how to make drones effectively project intelligible audio using onboard loudspeakers in noisy environments.
The major challenge identified is the extremely low signal-to-drone noise ratio (SDNR)—often worse than -10 dB—caused by rotor noise, which masks the playback of speech signals. Previous works in the field focused on drone-based sound localization, source separation, and signal enhancement, but very few examined audio output modeling for speech projection from UAVs.
The authors propose a sparsity-based interior response model for commercial loudspeakers mounted on drones. Unlike conventional models, this approach:
Accounts for multipath reflections (particularly from the ground),

Models the spatial response of the loudspeaker in outdoor-like conditions,

Uses Lasso regression to derive a sparse set of equivalent point sources,

Validates the model via spatial soundfield recordings in a controlled, semi-outdoor environment (anechoic chamber with artificial grass).

This is one of the first studies to quantitatively validate a loudspeaker model tailored for UAV speech transmission. The authors achieve low modeling errors (below −23 dB for coefficients) at frequencies up to 114 Hz, laying the foundation for future drone communication systems that combine loudspeaker modeling with text-to-speech synthesis and adaptive filtering to enhance intelligibility.
By building on and extending the point source models in acoustic signal processing , the research contributes a practical framework that can lead to the development of UAVs capable of direct vocal interaction in public safety, rescue missions, and crowd communication scenarios.


